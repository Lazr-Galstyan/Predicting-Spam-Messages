{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Spam Messages.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIgcrs3e6-Qb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aaf9964b-338b-4c79-89b0-4243d4ca2118"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjQVNwXGNnU8",
        "colab_type": "text"
      },
      "source": [
        "Every day we get different messages. There are different algorithm that are used to categorize those messages as ham and spam. In this analysis, I will try to predict whether or not the message is spam. I will use the dataset provided by UC Irvince, which you can find here: https://archive.ics.uci.edu/ml/datasets/sms+spam+collection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTmPJMRgyYYU",
        "colab_type": "text"
      },
      "source": [
        "###**Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1A7E1-7ylUw",
        "colab_type": "text"
      },
      "source": [
        "First I need to import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DhNSV8E7aBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWO-t8am8fe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the dataset\n",
        "df = pd.read_table('/content/drive/My Drive/NLP/SMSSpamCollection', header = None, encoding = 'utf-8')\n",
        "# Note: The code above is the  direction to my google drive, so it can be different for you."
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFmK0FfTy01F",
        "colab_type": "text"
      },
      "source": [
        "First, I will see how the dataset looks like, what are the variables, are there any missing values, and shape of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea39XHwOT1IK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b5f9652f-8cf3-433a-9f50-cd9deebfd081"
      },
      "source": [
        "# Check the first 5 rows\n",
        "df.head()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0                                                  1\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEgXFrssd3nK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1f9e6d39-0fbc-4d6a-d14d-41a911a32b06"
      },
      "source": [
        "# Check the unique values of the dataframe\n",
        "df.nunique()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2\n",
              "1    5169\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-bxawK2cZEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "91c4d6a1-a8fb-45e2-cc05-64e504056ce1"
      },
      "source": [
        "# Check sum of missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GroektEeT1LT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d8977e7-1b71-490c-fc7b-bc065846f384"
      },
      "source": [
        "# Check the shape of df\n",
        "df.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ0UJe6kUF_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "83a6abf6-b8fd-4d43-9272-f16eadb4f2ef"
      },
      "source": [
        "# Get info about the dataframe\n",
        "df.info()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       5572 non-null   object\n",
            " 1   1       5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLU3pTIYbaug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f50e980c-fa0e-4b6c-be6b-872a0d11ca1f"
      },
      "source": [
        "# Check number of ham and spam mails\n",
        "classes = df[0]\n",
        "print(classes.value_counts())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ham     4825\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iHfHCRfzHI4",
        "colab_type": "text"
      },
      "source": [
        "Note: The number spam messages is relatively small, which means that if I take all the messages as ham, then I will have around 87% accuracy (number of ham)/(number of total) * 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYh3yp5_T1Tv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "216d346c-4e36-4d5d-b88e-111f01cc1233"
      },
      "source": [
        "# Check the names of columns of df\n",
        "df.columns"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([0, 1], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUeKfVNR0RGA",
        "colab_type": "text"
      },
      "source": [
        "To start the analysis, I need to convert ham and spam to 0 and 1. The following function performs that operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gfZSAKy9q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert ham and spam to 0 and 1\n",
        "def convert(row):\n",
        "  if row[0] == \"ham\":\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "df['spam'] = df.apply(convert, axis=1)\n",
        "df = df.drop([0], axis=1)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFL_SiaiT1We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the duplicates\n",
        "df.drop_duplicates(inplace = True)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuZinOVteAFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset Index\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LgJ_Mw5T1cH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b3e9d96-6fc3-4661-9630-085941f2fb6a"
      },
      "source": [
        "# Check the shape of df\n",
        "df.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5169, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wJdANUV0piL",
        "colab_type": "text"
      },
      "source": [
        "After applying the function to the dataset, I dropped the duplicate rows and changed the indexed to start from 0 again. As I removed the duplicate rows, the number of rows decreases from 5572 to 5169."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZmcaQz5Egre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5d4cfa2f-6638-4d41-be58-3eae85608f22"
      },
      "source": [
        "# Check number of ham and spam mails\n",
        "classes = df['spam']\n",
        "print(classes.value_counts())"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    4516\n",
            "1     653\n",
            "Name: spam, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltbkjK72cHR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "be5582ae-a74a-4f7c-e0f5-1451cf64eb8c"
      },
      "source": [
        "# Check the tail of dataset\n",
        "df.tail()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5164</th>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5165</th>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5166</th>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      1  spam\n",
              "5164  This is the 2nd time we have tried 2 contact u...     1\n",
              "5165               Will ü b going to esplanade fr home?     0\n",
              "5166  Pity, * was in mood for that. So...any other s...     0\n",
              "5167  The guy did some bitching but I acted like i'd...     0\n",
              "5168                         Rofl. Its true to its name     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLOYmh2RdE5w",
        "colab_type": "text"
      },
      "source": [
        "##**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WePOBI-fdOEL",
        "colab_type": "text"
      },
      "source": [
        "I need to remove htmls, email addresses, phone numbers, money signs, numbers, punctuations, white spaces, and leading and tailing white spaces. The reason is that I need to see if the occurance of email of phone number and not a specific email/phone number can indicate whether or not the email is spam. Also, I need to make all the words lowercase (\"he\" and \"He\" have the same meaning), remove the sropwords (is, which, this, etc) and lexicon Normalization (\"car\" and \"cars\" have the same meaning). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lp3ldVqdNRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take the text column\n",
        "text_messages = df[1]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5tS0VkenSYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lem = WordNetLemmatizer()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMFk0rCH9lhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c0f403bf-8ab8-43a8-8ee9-8a9655f3b6ad"
      },
      "source": [
        "# Download stopwords and wordnet\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDqZCBK59mpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import stopwords\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsQp0Zmm2VLn",
        "colab_type": "text"
      },
      "source": [
        "To replace email address or phone numbers, I used regular expressions. I used the following website: http://regexlib.com/Search.aspx to get the necessary expressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foonYIxadLOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a function to conduct text preprocessing\n",
        "def preprocess(text):\n",
        "    assert(type(text) == str)\n",
        "    # Replace email addresses with emailaddr\n",
        "    processed = re.sub(r'^.+@[^\\.].*\\.[a-z]{2}$', 'emailaddr', text)\n",
        "    \n",
        "    # Replace urls with webaddress\n",
        "    processed = re.sub(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddr', processed)\n",
        "    \n",
        "    # Replace money symbols with money\n",
        "    processed = re.sub(r'£|\\$', 'money', processed)\n",
        "\n",
        "    # Replace phone numbers with phone\n",
        "    processed = re.sub(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phone', processed)\n",
        "    \n",
        "    # Replace numbers with 'number'\n",
        "    processed = re.sub(r'\\d+(\\.\\d+)?', 'number', processed)\n",
        "    \n",
        "    # Remove punctutations\n",
        "    processed = re.sub(r'[^\\w\\d\\s]', ' ', processed.lower())\n",
        "    \n",
        "    return ' '.join(\n",
        "        lem.lemmatize(term) \n",
        "        for term in processed.split()\n",
        "        if term not in set(stop_words)\n",
        "    )"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctA_T9mO9IdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ca2d5b89-c9d0-48a6-a183-498b994c466b"
      },
      "source": [
        "# Apply the function on the text data\n",
        "text_messages.apply(preprocess)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       go jurong point crazy available bugis n great ...\n",
              "1                                 ok lar joking wif u oni\n",
              "2       free entry number wkly comp win fa cup final t...\n",
              "3                     u dun say early hor u c already say\n",
              "4                     nah think go usf life around though\n",
              "                              ...                        \n",
              "5164    numbernd time tried number contact u u moneynu...\n",
              "5165                          ü b going esplanade fr home\n",
              "5166                                 pity mood suggestion\n",
              "5167    guy bitching acted like interested buying some...\n",
              "5168                                       rofl true name\n",
              "Name: 1, Length: 5169, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTQSFQJcXzWp",
        "colab_type": "text"
      },
      "source": [
        "##**Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnAWMHecX9Jj",
        "colab_type": "text"
      },
      "source": [
        "After cleaning the data, I need to perform feature engineering. First, I need to tokenize the data. I can tokenize not only each word or each sentence, but also pair of words. For example, bigram is when a pair of two words is taken as a token. The advantage of bigram is that it will be able to capture the meaning better. I will do unigram and bigram, and then will calculate tf-idf statistics to see the frequency of each token in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWjsQLgyX7m_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "59c4a127-58ea-4846-9b22-7663b9f3263d"
      },
      "source": [
        "# Import TFidfVectorizer to calculate tf-idf statistics. I use ngram_range as 1 and 2 to take unigram and bigram \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "n_grams = vectorizer.fit_transform(text_messages)\n",
        "print(n_grams)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 3447)\t0.19481166213785306\n",
            "  (0, 17542)\t0.19481166213785306\n",
            "  (0, 42108)\t0.19481166213785306\n",
            "  (0, 9517)\t0.19481166213785306\n",
            "  (0, 7585)\t0.19481166213785306\n",
            "  (0, 23683)\t0.19481166213785306\n",
            "  (0, 48759)\t0.19481166213785306\n",
            "  (0, 17853)\t0.19481166213785306\n",
            "  (0, 7591)\t0.19481166213785306\n",
            "  (0, 21112)\t0.19481166213785306\n",
            "  (0, 31375)\t0.18589385203479303\n",
            "  (0, 5433)\t0.19481166213785306\n",
            "  (0, 10748)\t0.19481166213785306\n",
            "  (0, 33489)\t0.19481166213785306\n",
            "  (0, 22943)\t0.19481166213785306\n",
            "  (0, 45051)\t0.19481166213785306\n",
            "  (0, 17168)\t0.19481166213785306\n",
            "  (0, 46559)\t0.1089915740494989\n",
            "  (0, 3446)\t0.19481166213785306\n",
            "  (0, 17535)\t0.09113128303211691\n",
            "  (0, 42067)\t0.09330658180194616\n",
            "  (0, 9510)\t0.1643214680072348\n",
            "  (0, 7584)\t0.18589385203479303\n",
            "  (0, 23682)\t0.1643214680072348\n",
            "  (0, 48749)\t0.13756803769805487\n",
            "  :\t:\n",
            "  (5167, 11906)\t0.1009052492406862\n",
            "  (5167, 28961)\t0.11421857769983029\n",
            "  (5167, 6034)\t0.07814420589252409\n",
            "  (5167, 15387)\t0.13984547406511025\n",
            "  (5167, 41209)\t0.05632770674862126\n",
            "  (5167, 15284)\t0.06671397532005792\n",
            "  (5167, 38370)\t0.1012736273064936\n",
            "  (5167, 24453)\t0.08738024283035987\n",
            "  (5167, 3594)\t0.06144907055147465\n",
            "  (5167, 46967)\t0.1044793846266083\n",
            "  (5167, 22150)\t0.06700259857491073\n",
            "  (5167, 19013)\t0.09345268978831969\n",
            "  (5167, 43120)\t0.046101584633524546\n",
            "  (5167, 15745)\t0.08887001722349439\n",
            "  (5167, 21062)\t0.0615889578855132\n",
            "  (5168, 22518)\t0.36263830324098545\n",
            "  (5168, 43433)\t0.36263830324098545\n",
            "  (5168, 44446)\t0.36263830324098545\n",
            "  (5168, 35658)\t0.36263830324098545\n",
            "  (5168, 22563)\t0.32512401173135824\n",
            "  (5168, 35656)\t0.3342598372300761\n",
            "  (5168, 44430)\t0.26090256676388535\n",
            "  (5168, 22448)\t0.3511089705609856\n",
            "  (5168, 28497)\t0.23897766178716107\n",
            "  (5168, 43120)\t0.08989216270059143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0RjsxEZed6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdeabde0-c82e-4713-a5ac-b977dd5937c7"
      },
      "source": [
        "# Check the shape of the final data\n",
        "n_grams.shape"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5169, 50506)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDzDCqArDD3r",
        "colab_type": "text"
      },
      "source": [
        "##**Build Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WebLrPmKpFBD",
        "colab_type": "text"
      },
      "source": [
        "I will make different models to see which one is better for prediction. First, we will try SVM model. I will try different parameters and will do grid search to find the optimal ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJUzO_Xv5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import GridSearchCV and SVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJms8kcByZYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the parameters, SVM, and the model\n",
        "# Parameters\n",
        "param_grid = {'C': [1, 2, 3],\n",
        "              'kernel': [ 'linear', 'sigmoid']}\n",
        "# Make the SVM\n",
        "svm = svm.SVC()\n",
        "\n",
        "# Model\n",
        "grid = GridSearchCV(estimator=svm, param_grid=param_grid, scoring='f1', cv=5)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yx5I6CU4Kfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e005ab8-96c8-4ea4-d2dc-534e053bb40e"
      },
      "source": [
        "# Fit the model and find the best parameters\n",
        "# Fit Model\n",
        "grid.fit(n_grams, df['spam'])\n",
        "\n",
        "# Get the best parameters\n",
        "print(\"Best Parameters: \", grid.best_params_)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:  {'C': 2, 'kernel': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4velDsV1glj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make SVM with the best parameters\n",
        "from sklearn import svm\n",
        "svm = svm.SVC(C = 2, kernel = 'sigmoid')"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irt60VT0glo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5584fb0-92cf-4165-b1ac-8a1c0f92bb78"
      },
      "source": [
        "# Run SVM and get the scores for 5-fold cross validation\n",
        "scores = cross_val_score(\n",
        "    estimator=svm,\n",
        "    X=n_grams,\n",
        "    y=df['spam'],\n",
        "    cv=5\n",
        ")\n",
        "scores"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98065764, 0.98259188, 0.98162476, 0.97969052, 0.98257502])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J83a-HmDglxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b1c4c64-4c17-49fc-8fde-e97081f3ca93"
      },
      "source": [
        "# Take the average of the scores\n",
        "scores.mean()*100"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.14279642213155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbkkKcAuGeui",
        "colab_type": "text"
      },
      "source": [
        "With SVM I get around 98% accuracy. Note again that the data are not well balanced and there are 4516 ham and 653 spam emails, which means that by assigning all the emails as ham I would get 87% accuracy. I will make the confustion matrix to see which parameters are predicted incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lsn5GITgl3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into train test 80/20\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(n_grams, df['spam'], test_size = 0.2, random_state = 123)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6RXovBIglz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model on train dataset\n",
        "svm1 = svm.fit(X_train, y_train)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqwiobcnglu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ef02f664-bc64-488e-b139-c0f409d5ab44"
      },
      "source": [
        "# Make the confustion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "svm_pred = svm1.predict(X_test)\n",
        "print(confusion_matrix(y_test, svm_pred))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[909   2]\n",
            " [ 17 106]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU9972VJ95t5",
        "colab_type": "text"
      },
      "source": [
        "From the matrix above I can see that the errors are mainly associated with False Positives. This means that sometimes the algorithm predicts a message to be spam, even though it is ham. Next, I will try random forest model to see how good it predicts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onMdgkTU-OGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU8NnMX_9444",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the parameters, RF, and the model\n",
        "params= {#'bootstrap': [True, False],\n",
        "         'max_depth': [100],\n",
        "         'n_estimators': [300, 400]}\n",
        "\n",
        "# Make the RF\n",
        "RandomForestClassifier = RandomForestClassifier()\n",
        "\n",
        "# Model\n",
        "gridRF = GridSearchCV(estimator=RandomForestClassifier, param_grid=params, scoring='f1', cv=5)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ5eJo28535N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19f0bba3-81e2-4dbf-8c73-d4e3e53dc7f0"
      },
      "source": [
        "# Fit the model and find the best parameters\n",
        "# Fit Model\n",
        "gridRF.fit(n_grams, df['spam'])\n",
        "\n",
        "# Get the best parameters\n",
        "print(\"Best Parameters: \", gridRF.best_params_)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:  {'max_depth': 100, 'n_estimators': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXZPFCfM5383",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make RF with the best parameters\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RandomForestClassifier = RandomForestClassifier(max_depth = 100, n_estimators = 300)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ7RYds_532t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76d8efb2-c0a4-4856-c3b3-fee2f08a7f21"
      },
      "source": [
        "# Run RF and get the scores for 5-fold cross validation\n",
        "scoresRF = cross_val_score(\n",
        "    estimator=RandomForestClassifier,\n",
        "    X=n_grams,\n",
        "    y=df['spam'],\n",
        "    cv=5\n",
        ")\n",
        "scoresRF"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97388781, 0.97195358, 0.96615087, 0.95841393, 0.96030978])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iZoX7qnglmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61c2e24d-dbbe-4714-8668-34f41f5ef2fe"
      },
      "source": [
        "# Take the average of the scores\n",
        "scoresRF.mean()*100"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.61431933805315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vopix3wMglhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model on train dataset\n",
        "RandomForestClassifier1 = RandomForestClassifier.fit(X_train, y_train)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sn4BMOWcCAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2d083f3-4277-4af3-cba5-6489440bd76b"
      },
      "source": [
        "# Make the confustion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "RF_pred = RandomForestClassifier1.predict(X_test)\n",
        "print(confusion_matrix(y_test, RF_pred))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[911   0]\n",
            " [ 36  87]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTX2A-pClwjP",
        "colab_type": "text"
      },
      "source": [
        "I used grid search for RF as well. However, I did not try many parameters as it takes too long to run and I would recommend trying more parameters if you have more computing power. As a result, I got 96% accuracy (lower than SVM). By looking at the confusion matrix you see that again the False Positives are the main causes of errors. Next I will try a relatively simple, Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8iTUTQZcCS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the package\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(random_state=0)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6wQFW5iqJr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1cee0af-5fdd-4793-ac30-13f09582b15b"
      },
      "source": [
        "# Conduct 5 fold cross validationa and get the scores\n",
        "scoresLR = cross_val_score(\n",
        "    estimator=LR,\n",
        "    X=n_grams,\n",
        "    y=df['spam'],\n",
        "    cv=5\n",
        ")\n",
        "scoresLR"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.93617021, 0.92553191, 0.93617021, 0.92843327, 0.93223621])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXrsPNxxqDAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d401b289-cd60-484d-af39-a500f8b509f2"
      },
      "source": [
        "# Calculate the average score for LR\n",
        "scoresLR.mean()*100"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.17083629023651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxvDOOHKPKMf",
        "colab_type": "text"
      },
      "source": [
        "As you can see, a realitvely simple model does not predict well, and next I will try more advance model: XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h9vcQ3jrFBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import XGBoost\n",
        "import xgboost as xgb"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oa_ntRDQtrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make the parameters, XGBoost, and the model\n",
        "# Parameters\n",
        "param_gridxgb = {'learning rate': [0.1, 0.5],\n",
        "              'n_estimators': [400],\n",
        "              'subsample': [0.75, 0.85],\n",
        "              'colsample_bytree':[0.5, 0.7],\n",
        "              'reg_alpha':[0.001, 0.003]}\n",
        "\n",
        "# XGBoost\n",
        "xgbm = xgb.XGBClassifier()\n",
        "\n",
        "# Model\n",
        "grid_xgb = GridSearchCV(estimator=xgbm, param_grid=param_gridxgb, scoring='f1', cv=5)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGXw03QNRmav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "720e9631-e17c-48a2-faa0-fa9d0f838872"
      },
      "source": [
        "# Fit the model and find the best parameters\n",
        "# Fit Model\n",
        "grid_xgb.fit(n_grams, df['spam'])\n",
        "\n",
        "# Get the best parameters\n",
        "print(\"Best Parameters: \", grid_xgb.best_params_)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters:  {'colsample_bytree': 0.7, 'learning rate': 0.1, 'n_estimators': 400, 'reg_alpha': 0.003, 'subsample': 0.85}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8XNREq4cCH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make RF with the best parameters\n",
        "import xgboost as xgb\n",
        "spam_model_xgboost = xgb.XGBClassifier(learning_rate = 0.1, n_estimators = 400, subsample = 0.85, colsample_bytree=0.7, reg_alpha=0.003)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYUYyYqScCFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "935693ad-66a5-4120-e412-681375e165fc"
      },
      "source": [
        "# Run RF and get the scores for 5-fold cross validation\n",
        "scoresXGB = cross_val_score(\n",
        "    estimator=spam_model_xgboost,\n",
        "    X=n_grams,\n",
        "    y=df['spam'],\n",
        "    cv=5\n",
        ")\n",
        "scoresXGB"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9787234 , 0.97969052, 0.98162476, 0.9729207 , 0.9767667 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FWTmi3dcCDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "870d5391-8a5c-4b51-b0dd-8b60b1eecfc7"
      },
      "source": [
        "# Take the average of the scores\n",
        "scoresXGB.mean()*100"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.79452159959256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NdtBSxhrLdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model on train dataset\n",
        "spam_model_xgboost1 = spam_model_xgboost.fit(X_train, y_train)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj7YNn8xs1lO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9990cd2b-77fc-4f61-b08d-22b9706e046e"
      },
      "source": [
        "# Make the confustion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "RF_pred = spam_model_xgboost1.predict(X_test)\n",
        "print(confusion_matrix(y_test, RF_pred))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[909   2]\n",
            " [ 19 104]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A79_YmOlKjzO",
        "colab_type": "text"
      },
      "source": [
        "Overall, after trying XGBoost, Logistic Regression, Random Forest, and SVM, I found that SVM model has the highest accuracy (around 98%). The errors are associated mainly with False Positives, when the algorithm predicts messages to be spam, even though they are not. The reason why SVM performs better than XGBoost can be the low number of observations (5,169 in total)."
      ]
    }
  ]
}